%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Diaz Essay
% LaTeX Template
% Version 2.0 (13/1/19)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Nicolas Diaz (nsdiaz@uc.cl)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{diazessay} % Font size (can be 10pt, 11pt or 12pt)
\usepackage{mathptmx}
\usepackage{setspace}
% for author-year citation style
\usepackage[round]{natbib}
\bibliographystyle{plainnat}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\textbf{Quora Insincere Questions Classification} \\ {\Large\itshape A Sentiment Analysis Focusing on Quora}} % Title and subtitle

\author{\textbf{Mengxuan Lyu, Jinyue Feng} \\ \textit{University of Toronto}} % Author and institution

\date{\today} % Date, use \date{} for no date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

%----------------------------------------------------------------------------------------
%	ABSTRACT AND KEYWORDS
%----------------------------------------------------------------------------------------

%\renewcommand{\abstractname}{Summary} % Uncomment to change the name of the abstract to something else

% \begin{abstract}
% Morbi tempor congue porta. Proin semper, leo vitae faucibus dictum, metus mauris lacinia lorem, ac congue leo felis eu turpis. Sed nec nunc pellentesque, gravida eros at, porttitor ipsum. Praesent consequat urna a lacus lobortis ultrices eget ac metus. In tempus hendrerit rhoncus. Mauris dignissim turpis id sollicitudin lacinia. Praesent libero tellus, fringilla nec ullamcorper at, ultrices id nulla. Phasellus placerat a tellus a malesuada.
% \end{abstract}

% \hspace*{3.6mm}\textit{Keywords:} lorem, ipsum, dolor, sit amet, lectus % Keywords

% \vspace{30pt} % Vertical whitespace between the abstract and first section

%----------------------------------------------------------------------------------------
%	ESSAY BODY
%----------------------------------------------------------------------------------------
\doublespacing % double space
\section*{Literature Review}



% for citation, use \citep{} instead of \cite
A related question to insincere questions classification is sarcasm detection, which is a frequently researched area in sentiment analysis\citep{joshi2017}. Sarcastic messages and insincere questions share many similarities in terms of their linguistic nature:

\begin{enumerate}
	\item \textbf{Sentiment Involvement:} Both sarcasm and rhetorical questions involve non-neutral sentiment under the disguise of a propositional or interrogative structure \citep{joshi2017, schmidt1977}. 
	\item \textbf{Presence of Indicative Words:} One type of insincere questions contain expressions of excusive absoluteness, such as \textit{``if not"}; other rhetorical questions have non-deontic modal verbs and some other special particles that strongly indicate its persuative, not interrogative, nature \citep{schmidt1977}. Similarly, sarcastic texts also involve indicative words, such as \textit{`like'} in \textit{``like you understand"} \citep{joshi2017}. 
	\item \textbf{Dropped Negation:} Many sarcastic sentences and rhetorical questions are meant to make a negative statement despite the absence of negation words  \citep{joshi2017, schmidt1977}. For instances, ``Having a cold is so fun" means ``Having a cold is not fun at all", and ``Can such a man be innocent?" means ``Such a man cannot be innocent."
	\item \textbf{Intended Victim:} Sarcastic comments can be used to mock a victim, and insincere questions can be discriminative or irrespectful against certain groups of people. The hurtful components in both situations may be implicit or explicit. 
	\item \textbf{Violation of Truthfulness:} Sarcastic comments that violate truthfulness resemble insincere questions that are based on false premises. To understand these languages, the listener needs to know the violation of truthfulness \citep{joshi2017}. This can be a hard problem in natural language processing as it largely depends on knowledge about certain people or certain topics. However, it is also possible the untruthful texts have syntactic or semantic characteristics.  
\end{enumerate}

Here we review several studies on sarcasm detection in the hope of transferring core concepts and methods to insincere question classification.

- A deeper look into sarcastic tweets using deep convolutional neural networks
\citep{poria2017}

In this study, the researchers presented a CNN architecture that contained in parallel a baseline 2-layer CNN model that directly process the text and three pre-trained models covering three types of clues (in particular, sentiments, emotions and personalities) that could be beneficial for sarcasm detection. These pre-trained models were trained on their benchmark datasets and then used for feature extraction on the sarcastic tweets datasets. To merge the outputs of the four components, the researchers tested two methods: combining the outputs using SVM and appending extracted features from the pre-trained models into the baseline CNN hidden layers. The former method showed better results possibly because appending the extracted features into the baseline models compromised their meaningfulness. \\Although the baseline features (directly extracted from the word vectors) showed better predictions than all pre-trained models, the combination of the baseline and pre-trained models yielded the best performance. The result indicated that compared to completely distributing word representations, modularized components with specific tasks could improved the overall performance of a CNN model. Since we have established several characteristics that indicate a Quora question to be insincere, the idea of combining various components each responsible for detecting different classification clues can be valuable for our project. \\ One additional lesson from this study is that their CNN model with a relatively lower feature dimension (at 1,100) outperformed models using larger vector size (>500,000) both in terms of accuracy and computation speed. 

- Fracking Sarcasm using Neural Network \citep{ghosh2016}

This work presented a CNN-LSTM-DNN neural networks model for semantic modeling to detect sarcastic tweets. Consider that the information-bearing parts of a text could exit anywhere, the choice of convolutional neural networks and recurrent neural networks was reasonable as both CNN and RNN were capable of capturing temporal sequential information. Among RNN implementations, LSTMs were beneficial because of the easiness to train and the avoidance of vanishing or exploding gradients. The combination of CNN and RNN networks were also advantageous for the following reasons: 1) convolutional layer helped to extract abstract and compact features to be used as inputs to LSTM network; 2) LSTM compensates for the disadvantage of fixed filter width of convolutional layers, allowing for better analysis of long-distance relationships over texts with various length; 3) CNN could reduce feature variations so that CNN-LSTM worked more efficiently. On top of the LSTM layers, the researchers added a fully-connected DNN layer to map the features into a more separable space. The combination of CNN, LSTM, and DNN showed more superior results than recursive SVM, two-layer CNN, and two-layer RNN models. Consider the similarity between the tasks of this study and our project, we can construct our neural networks architecture following this CNN-LSTM pattern. 

- Robust Sentiment Detection on Twitter from Biased and Noisy Data \citep{barbosa2010}

This work presented a 2-step sentiment analysis method that only utilized an SVM model for machine learning process, but its feature extraction methods allowed for robustness against noisy data. The researchers developed two feature sets designed to provide abstract representations of short texts: meta-features (including PoS tags and prior subjectivity and polarity) and syntactic features (namely frequencies of certain types of characters). The detection process were divided into two parts: subjectivity detection and polarity detection of the subjective texts. The experiment followed a traditional approach where the classifiers with highest information gain were created using Weka and the learning process were completed using SVM algorithm. Although this method no longer offers state-of-art performance, we still consider the feature selection methods valuable to our project. We intend to adapt the design in this study to obtain measurements of corpus statistics to feed as features into our neural network models. 

- Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts \citep{santos2014}

Compared to long texts that contain more contextual information, short texts sentiment analysis can be more challenging and thus methods such as bag-of-words or n-grams are shown to be less effective\citep{barbosa2010, santos2014}. In this study, the researchers proposed a deep CNN model that constructed word embeddings from character-level to sentence-level for sentiment analysis. Compared to the four-component CNN model in \citep{poria2017} which horizontally extracted information from different aspects, this model specialized in obtaining textual information in depth. The character-level embeddings captured morphological information and the word-level embeddings catch syntactical and semantical information. Finally, the sentence-level representations were constructed upon concatenated character-level and word-level features. The word-level embeddings came from Word2Vec embeddings, and the character-level and sentence-level were obtained using convolutional layers that successively extracted local features in windows and maxed over these windows to get the global representation. According to the results, the extracted features at sentence-level typically concentrated on several sentiment-bearing keywords. On the other hand, the contributions of character-level representations were not closely examined, so to what degree morphological and shape information benefited sentiment analysis were not clear. 

- Are word embedding-based features useful for sarcasm detection? \citep{joshi2016}

This work examined how features calculated from word embedding vectors could augment existing feature sets including n-grams, dictionary-based features, syntactical features and pattern-based features. More specifically, the researchers attempted to use word vector distances to detect context incongruity independent of sentiment changes. The results indicated that word embedding-based features enhanced performance. This method might be useful in our project for two reasons: 1) insincere questions may also contain context incongruity because of conflict between asking a question while making a statement; 2) questions that have discriminative or sexual language may be detected based on the semantic similarities to a set of sensitive keywords.  In this system, known sources of errors include multiple-sense-induced embedding issues, incapability to detect contextual information, and non-sarcastic metaphors. We expect the latter two issues have lower impact on insincerity detection than sarcasm detection. 


\subsection*{Word Embeddings}
Before we feed the data into our models, we need to project it into vectors of real numbers. Therefore, we review some recent techiniques performing word embeddings and present here.

A critical obstacle of language modeling is caused by the curse of dimensionality. To address this problem, in 2003, \citep{bengio2003neural} proposed a feadforwad Neural Network Language Model (NNLM) to learn a dense distributed representation\citep{hinton1986learning} for words, where both the word feature vectors and the parameters of that probability function are learned at the same time. NNLM was designed to learn $f \left( w _ { t } , \cdots , w _ { t - n + 1 } \right) = \hat { P } \left( w _ { t } | w _ { 1 } ^ { t - 1 } \right)$, $w _ { t } \in V$, where $w_1 \cdots w_T$ is the word sequence and $V$ is a large but finite vocabulary. This objective is divided into two steps: firstly the previous N words would be mapped into real vectors by a share projection matrix, which represents each word of the vocabulary with a distributed feature vectors; then the sequence of word feature vectors would be mapped into a probability distribution over $V$. As a result, this model yielded better perplexity compared to N-gram models. and inspired more researchers looking into distributed representations of words.

Recognizing the need to include distributed representations of words which was introduced by \citep{hinton1984distributed}, \citep{mikolov2013efficient} analyzed NNLM and proposed two models to learn the words' continuous vector representations. Originally, NNLM mainly consists of three layers: words are firstly mapped into embeddings at project layer; then embedded vectors would flow into a ordinary hyperbolic tangent hidden layer; finally the output layer represents the probability distribution over $V$. Therefore, most of the computations happen in the output layer. To learn the continuous word representations with higher accuracy and lower computational cost from a very large corpus, the first model Mikolov et al. proposed is the Continuous Bag-of-Words Model (CBOW) which removes the non-linear hidden layer. In CBOW, embedded words would be first projected and then averaged into the same position, after which a output layer is presented with hierarchical softmax. Similar to CBOW, they also provided another model called Continuous Skip-gram Model to predict the context given a word. The result turned out to be promising as the model did not only capture the syntactic regularities, but also reveal subtle semantic information of words.


%------------------------------------------------

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliographystyle{unsrt}

\bibliography{csc2511.bib}

%----------------------------------------------------------------------------------------

\end{document}
