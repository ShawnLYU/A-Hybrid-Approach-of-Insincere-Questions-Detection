{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Total: 1306122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath_train = '../data/train.csv'\n",
    "df_train = pd.read_csv(filepath_train,index_col=0)\n",
    "print('training dataset size: ',df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['qid_base_hex'] = df_train.index\n",
    "df_train['qid_base_ten'] = df_train['qid_base_hex'].apply(lambda x : int(x, 16))\n",
    "\n",
    "msk = np.random.rand(len(df_train)) < 0.8\n",
    "\n",
    "train = df_train[msk][['question_text','target']]\n",
    "test = df_train[~msk][['question_text','target']]\n",
    "\n",
    "train.to_csv('../data/mytrain.csv')\n",
    "test.to_csv('../data/mytest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from train and test data and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/mytrain.csv')\n",
    "df_test = pd.read_csv('../data/mytest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['train_test'] = 'train'\n",
    "df_test['train_test'] = 'test'\n",
    "df = pd.concat([df_train, df_test])\n",
    "df['qid_base_ten'] = df['qid'].apply(lambda x : int(x, 16))\n",
    "\n",
    "\n",
    "min_qid = df['qid_base_ten'].min()\n",
    "df['qid_base_ten_normalized'] = df['qid_base_ten'].apply(lambda x : (x - min_qid)/min_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.clf()\n",
    "plt.figure(figsize=(18, 8));\n",
    "plt.scatter(x=df[df['train_test']=='train']['qid_base_ten_normalized'], y=[1]*df[df['train_test']=='train'].shape[0], label='Train', s=300);\n",
    "plt.scatter(x=df[df['train_test']=='test']['qid_base_ten_normalized'], y=[1]*df[df['train_test']=='test'].shape[0], label='Test',s=2);\n",
    "plt.xlabel('qid_base_ten_normalized');\n",
    "plt.ylabel('N/A');\n",
    "plt.title('qid_base_ten_normalized for train and test datasets')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally the reading of training and testing data would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('../data/mytrain.csv')\n",
    "df_test = pd.read_csv('../data/mytest.csv')\n",
    "# or read qid as index:\n",
    "# df_train = pd.read_csv('../../data/mytrain.csv',index_col=0)\n",
    "# df_test = pd.read_csv('../../data/mytest.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats over corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_train['question_text'].values\n",
    "sen_len = [len(line.split()) for line in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min len:',min(sen_len))\n",
    "print('Max len:',max(sen_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(sen_len, bins =  np.arange(0,140,2)) \n",
    "plt.title(\"histogram\") \n",
    "plt.xlabel('Sentence lens')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokenized_sen = [re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE) for text in sentences]\n",
    "token_len = [len(e) for e in tokenized_sen]\n",
    "print('Min len:',min(token_len))\n",
    "print('Max len:',max(token_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len.sort()\n",
    "x = range(600)\n",
    "y = []\n",
    "prev = 0\n",
    "for e in x:\n",
    "    try:\n",
    "        prev = token_len.index(e)\n",
    "        y.append(token_len.index(e))\n",
    "    except:\n",
    "        y.append(prev)\n",
    "\n",
    "y_percent = [e/len(token_len) for e in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_percent, 'ro')\n",
    "plt.title(\"Percentage\") \n",
    "plt.xlabel('Number of tokens')\n",
    "plt.ylabel('Percentages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1-y_percentage[100])*len(token_len) = 22`, which means only about 22 sentences are longer than 100 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with mytrain.csv and mytest.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels of samples with \\[math\\] that need to be modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Proper math questions that were classified as insincere by Quora:  \n",
    "`[[22402,0],\n",
    "[30914,0],\n",
    "[101048,0],\n",
    "[131075,0],\n",
    "[134731,0],\n",
    "[185318,0],\n",
    "[224464,0],\n",
    "[262046,0],\n",
    "[267327,0],\n",
    "[354833,0],\n",
    "[405552,0],\n",
    "[407980,0],\n",
    "[422950,0],\n",
    "[583645,0], \n",
    "[584827,0],\n",
    "[649125,0],\n",
    "[731531,0],\n",
    "[848889,0],\n",
    "[875208,0], \n",
    "[930275,0], \n",
    "[972559,0], \n",
    "[976850,0], \n",
    "[1007192,0], \n",
    "[1012853,0], \n",
    "[1044032,0]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To change the label accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('../data/mytrain.csv')\n",
    "list_to_be_handled = [[22402,0],\n",
    "[30914,0],\n",
    "[101048,0],\n",
    "[131075,0],\n",
    "[134731,0],\n",
    "[185318,0],\n",
    "[224464,0],\n",
    "[262046,0],\n",
    "[267327,0],\n",
    "[354833,0],\n",
    "[405552,0],\n",
    "[407980,0],\n",
    "[422950,0],\n",
    "[583645,0], \n",
    "[584827,0],\n",
    "[649125,0],\n",
    "[731531,0],\n",
    "[848889,0],\n",
    "[875208,0], \n",
    "[930275,0], \n",
    "[972559,0], \n",
    "[976850,0], \n",
    "[1007192,0], \n",
    "[1012853,0], \n",
    "[1044032,0]]\n",
    "for [ind, target] in list_to_be_handled:\n",
    "    print('%d orginal target %d changing to ' % (ind,df_train.iloc[ind].target),end='')\n",
    "    df_train.loc[ind,'target'] = target\n",
    "    print(df_train.iloc[ind].target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove sentences with newline characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_train['question_text'].values\n",
    "is_newline = [1 if '\\n' in e else 0 for e in sentences] # there are 6 sentences containing \\n\n",
    "df_train_newline_removed = df_train[~df_train.question_text.str.contains('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Since there are around 20 sentences with more than 100 tokens, to speed up training process, remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "########################### following code compares regex vs spacy in terms of tokenization\n",
    "tokens = [re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE) for text in df_train_newline_removed.question_text.values]\n",
    "\n",
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "        SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words(x)]\n",
    "\n",
    "tokens_spacy=[]\n",
    "for i in range(len(df_train_newline_removed.question_text.values)):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    tokens_spacy.append(tokenizer(df_train_newline_removed.question_text.values[i]))\n",
    "\n",
    "import numpy as np\n",
    "tokens_np = np.array(tokens)\n",
    "tokens_spacy_np = np.array(tokens_spacy)\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    if tokens_np[i] != tokens_spacy_np[i]:\n",
    "        print(i,tokens_np[i],tokens_spacy_np[i])\n",
    "\n",
    "######################### Apparently spacy makes more sense        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "df_train_newline_removed['tokens'] = tokens_spacy\n",
    "token_len = [len(e) for e in tokens]\n",
    "df_train_newline_removed['token_len'] = token_len\n",
    "df_train_filtered = df_train_newline_removed[df_train_newline_removed['token_len']<=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally file contains 1044886 rows\n",
      "There are 1044865 samples\n",
      "After removing data containing newline, there are 1044859 samples\n",
      "After removing data with more than 100 tokens, there are 1044839 samples\n"
     ]
    }
   ],
   "source": [
    "print('Originally file contains %d rows' % 1044886)\n",
    "print('There are %d samples' % df_train.shape[0])\n",
    "print('After removing data containing newline, there are %d samples' % df_train_newline_removed.shape[0])\n",
    "print('After removing data with more than 100 tokens, there are %d samples' % df_train_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Join tokens so that each word and punctuations are separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_join(row):\n",
    "    return ' '.join(row['tokens'])\n",
    "\n",
    "df_train_filtered['tokenized'] = df_train_filtered.apply(lambda row: token_join(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write question texts into file for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"insincere\" has a value of 1, otherwise 0\n",
    "sincere = [1 if e == 0 else 0 for e in df_train_filtered.target]\n",
    "insincere = [0 if e == 0 else 1 for e in df_train_filtered.target]\n",
    "df_train_filtered['sincere'], df_train_filtered['insincere'] = sincere, insincere\n",
    "df_train_filtered.to_csv('filtered_train_data_all.csv')\n",
    "np.savetxt('train_no_newline_no_quote_tokenized',df_train_filtered.tokenized.values,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
