{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and read embeddings len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('len_file', 'wb') as fp:\n",
    "    pickle.dump(sen_len, fp)\n",
    "\n",
    "with open ('len_file', 'rb') as fp:\n",
    "    sen_len = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max(sen_len)`: 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('/u/shawnlyu/projects/linguistics/workdir/cleaned_data/se100_newlineremoved_text',index_col=0)\n",
    "labels = list(df_train.target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len(labels)`: 1, 044, 839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "DATA_ROOT = '/u/shawnlyu/projects/linguistics/workdir/embeddings/elmo_layers.train.hdf5'\n",
    "with h5py.File(DATA_ROOT,'r') as hf:\n",
    "    dataset_names = list(hf.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len(dataset_names)`: 1, 044, 840"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5py_file.get(\"0\")` 0 - 1, 044, 838 for embeddings of each sentences    \n",
    "`h5py_file.get(\"sentence_to_index\")` for sentence and index relations (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py_file = h5py.File(DATA_ROOT, 'r')\n",
    "sen_len = []\n",
    "for i in range(1044839):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    sen_len.append(h5py_file.get(str(i)).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "config = Config(\n",
    "    # information about dataset\n",
    "    training_size=1044839,\n",
    "    word_embeddings_dim=512,\n",
    "    sen_len=65, # this should be larger than max-sen-len declared at the top\n",
    "    \n",
    "    # pytorch settings    \n",
    "    seed=1,\n",
    "    \n",
    "    # neural nets params\n",
    "    dataLoader={\n",
    "    'batch_size': 128,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 20,\n",
    "    },\n",
    "    lr=3e-4,\n",
    "    epochs=10,\n",
    "    hidden_sz=64,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement dataloader for sequential loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = h5py_file.get(ID)\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "# Generators\n",
    "IDs = [str(i) for i in range(config.training_size)]\n",
    "training_set = Dataset(IDs, labels)\n",
    "training_generator = data.DataLoader(training_set, **config.params)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F     # functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim):\n",
    "        super(CNN_LSTM,self).__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=(config.sen_len,config.word_embeddings_dim))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(config.sen_len,config.word_embeddings_dim))\n",
    "        self.lstm = nn.LSTM(input_size,hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim,1)\n",
    "        self.hidden = self.init_hidden()\n",
    " \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    " \n",
    "    def forward(self,seq):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            seq.view(len(seq), 1, -1), self.hidden)\n",
    "        outdat = self.hidden2out(lstm_out.view(len(seq),-1))\n",
    "\n",
    "\n",
    "net = Net(n_feature=1, n_hidden=10, n_output=1)\n",
    "\n",
    "print(net)\n",
    "\"\"\"\n",
    "Net (\n",
    "  (hidden): Linear (1 -> 10)\n",
    "  (predict): Linear (10 -> 1)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
