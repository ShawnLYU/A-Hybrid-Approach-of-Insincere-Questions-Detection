{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = '../data/mytrain.csv'\n",
    "filepath = 'toy_set.csv' # a small set of 2000 questions for testing\n",
    "df_data = pd.read_csv(filepath)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "PUNCT_DICT = {'all_punctuation': string.punctuation, 'commas': ',', \\\n",
    "'periods': '.', 'quotation_marks': '\\'\\\"', 'question_marks': '?', \\\n",
    "'exclamation_marks': '!', 'other_punctuations': [s for s in string.punctuation if s not in ',.\\'\\\"?!']}\n",
    "\n",
    "POS_LIST = ['ADJ', 'ADV', 'INTJ', 'NOUN', 'PROPN', 'VERB', 'ADP', 'AUX', \\\n",
    "'CCONJ', 'DET', 'NUM', 'PART', 'PRON', 'SCONJ', 'SYM', 'X']\n",
    "# Reference: https://universaldependencies.org/u/pos/\n",
    "\n",
    "ENT_LIST = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', \\\n",
    "'WORK_OF_ART', 'LAW', 'LANGUAGE', 'DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY',\n",
    "'ORDINAL', 'CARDINAL']\n",
    "#reference: https://spacy.io/api/annotation#section-named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dictionaries for statistical information for one sentence\n",
    "\n",
    "- Currently this covers 3 aspects: punctuation, pos, and entities\n",
    "- The statistical information are all counts of occurrances \n",
    "    - **Might need more statistics?**\n",
    "- The lists of pos and entity types are cited below\n",
    "- Note that spacy provides a PUNCT tag in the pos-tagger, but here we define finer-grained categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_count_dict(sentence):\n",
    "\t\"\"\" Return count dictionaries for sentence mapping from labels to the count of words\n",
    "\tthat satisfies a corresponding condition: \n",
    "\t1 - char in char_type (punctuation)\n",
    "\t2 - taken.pos_ == pos (part of speech)\n",
    "\t3 - ent.label_ == ent (named entites)\n",
    "\t\"\"\"\n",
    "\tpunc = {key: 0 for key in PUNCT_DICT.keys()}\n",
    "\tpos = {pos: 0 for pos in POS_LIST}\n",
    "\tent = {ent: 0 for ent in ENT_LIST}\n",
    "\n",
    "\tdoc = nlp(sentence)\n",
    "\tents = doc.ents\n",
    "\n",
    "\tfor word in sentence:\n",
    "\t\tfor key, value in PUNCT_DICT.items():\n",
    "\t\t\tif word in value:\n",
    "\t\t\t\tpunc[key] += 1\n",
    "\n",
    "\tfor token in doc:\n",
    "\t\tif token.pos_ in POS_LIST:\n",
    "\t\t\tpos[token.pos_] += 1\n",
    "\n",
    "\tfor e in ents:\n",
    "\t\tif e.label_ in ENT_LIST:\n",
    "\t\t\tent[e.label_] += 1\n",
    "\n",
    "\treturn punc, pos, ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect statistical data for all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection(dataframe):\n",
    "\t\"\"\" Return statistical data of sentences with label, which is 0 for negative\n",
    "\tand 1 for positive. \n",
    "\t\"\"\"\n",
    "\tsentences = dataframe['question_text'].values\n",
    "\t# punctuations\n",
    "\tpunc = dict((key, []) for key in PUNCT_DICT.keys())\n",
    "\t# punc_count = dict((key, 0) for key in PUNCT_DICT.keys())\n",
    "\tpos = dict((pos, []) for pos in POS_LIST)\n",
    "\t# pos_count = dict((pos, 0) for pos in POS_LIST)\n",
    "\tent = dict((ent, []) for ent in ENT_LIST)\n",
    "\n",
    "\tdata_container = [punc, pos, ent]\n",
    "\n",
    "\tbar = Bar(\"Collecting data over sentences\", max=len(sentences))\n",
    "\tfor s in sentences:\n",
    "\t\t# punctuations\n",
    "\t\tpunc_dict, pos_dict, ent_dict = build_count_dict(s)\n",
    "\n",
    "\t\tdata = [punc_dict, pos_dict, ent_dict]\n",
    "\n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tfor key, value in data[i].items():\n",
    "\t\t\t\tdata_container[i][key].append(value)\n",
    "\n",
    "\t\tbar.next()\n",
    "\tbar.finish()\n",
    "    \n",
    "\tfor container in data_container:\n",
    "\t\tfor key, value in container.items():\n",
    "\t\t\tdataframe[key] = pd.Series(value, index=dataframe.index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sample KS Testing\n",
    "\n",
    "The purpose is to extract features of which the distributions in positive and negative datasets are significantly different. \n",
    "\n",
    "P-value threshold: 0.01 (standard for two-tailed test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(set1, set2, theme):\n",
    "\t\"\"\" Conduct KS test to compare set1 and set2. Print the results and return\n",
    "\tTrue iff set1 and set2 are significantly different at 0.001 level.  \n",
    "\n",
    "\tTheme is a text label for the comparison. \n",
    "\t\"\"\"\n",
    "\n",
    "\tks_test_score, ks_p_value = stats.ks_2samp(set1, set2)\n",
    "\n",
    "\tprint(\"===== KS test for {} =====\".format(theme))\n",
    "\n",
    "\tprint(\"KS statistic: {}\\np-value: {}\".format(ks_test_score, ks_p_value))\n",
    "\n",
    "\t# Since it is a two-tailed test, the difference is considered significant\n",
    "\t# when p value is smaller thatn 0.01\n",
    "\tif ks_p_value < 0.01:\n",
    "\t\tprint(\"The two distributions are significantly different. \")\n",
    "\t\treturn True\n",
    "\n",
    "\treturn False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the methods: main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting raw data from data_collection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdata_collection(df_data)\n",
    "\tdf_positive, df_negative = df_data[df_data['target']==1], df_data[df_data['target'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers for punctuation marks/PoS/entities counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'punctuation':[PUNCT_DICT.keys(), []], 'pos_tag':[POS_LIST, []], 'ent':[ENT_LIST, []]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting statistical info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in features.items():\n",
    "\t\tfor label in value[0]:\n",
    "\t\t\tif ks_test(df_positive[label].values, df_negative[label].values, label):\n",
    "\t\t\t\tvalue[1].append(label)\n",
    "\t\tdf = df_data[value[1]]\n",
    "\t\tdf['target'] = df_data['target']\n",
    "# \t\tfilename = '{}.csv'.format(key)\n",
    "# \t\tdf.to_csv(filename, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in features.items():\n",
    "\t\tprint('{} test results: {}'.format(key, value[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
